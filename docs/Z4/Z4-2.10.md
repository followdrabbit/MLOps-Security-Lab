# Z4-2.10 — **Validação em Staging, Shadow & Plano de Canary (pré-Z6)**

*o ensaio geral para garantir que o modelo “pronto” funciona sob tráfego real, com segurança, performance e governança*

Depois que o candidato passou por **Higiene (Z4-2.4)**, **Testes Adversariais (Z4-2.5)**, **Tracking/Proveniência (Z4-2.6)**, **Empacote/Assine (Z4-2.7)** e **Readiness Review (Z4-2.8)** — e você fez a **higiene pós-treino (Z4-2.9)** — executamos a **prova de figurino operacional**: validar o modelo **em Staging** (produção-like), medir riscos/latência/custo, fazer **Shadow Mode** (espelhamento de tráfego **sem impacto** no usuário) e preparar/rodar um **Canary Release** com **gatilhos de rollback** claros.
O objetivo é **provar que o modelo pode ir para Z6** respeitando **SLOs**, **políticas de segurança** e **limites de custo**.

---

## 1) Objetivos & Escopo

**Objetivos**

* Verificar **integração** do artefato assinado com o **runtime** de inferência (containers, sidecars, policies).
* Medir **latência/throughput/erro** sob carga realista e validar **SLOs** (p50/p95/p99).
* Exercitar **segurança de borda** (AuthN/AuthZ, mTLS, rate limit) e **guardrails** (LLM Gateway, filtros).
* Detectar **regressões de negócio** (KPIs) e **drifts imediatos** de distribuição/saídas.
* Ensaiar **rollback** e confirmar que **observabilidade** está completa (logs/métricas/traces).

**Escopo**

* **Staging**: ambiente isolado, produção-like (mesma imagem base, mesmos policies).
* **Shadow**: espelho de tráfego de produção para o candidato (somente leitura, **sem** efeito externo).
* **Canary**: liberação progressiva controlada (1% → 5% → 25% …) com **gates automáticos**.

---

## 2) Entradas & Pré-requisitos

* Versão do modelo no **Z5 (Registry)** com `security_decision=PASS`, **assinaturas válidas** e **attestation**.
* `model_card.md`, **SCDR/ADR**, `readiness_manifest.json`.
* **SLOs/SLIs definidos** (latência, erro, custo por 1k chamadas) e **limites de segurança** (políticas LLM, limites de score).

---

## 3) Itens de validação em **Staging**

### 3.1 Contrato de API & Schema

* **Request/Response JSON Schema** (ou Pydantic) válido; campos obrigatórios, tipos, *ranges*.
* **Headers** obrigatórios (AuthZ, correlação) presentes e auditáveis.
* **Back-compat** com consumidores (versões suportadas).

### 3.2 Segurança de borda (igual Z6)

* **mTLS** entre gateway e *pods*; **AuthN/AuthZ** (RBAC/ABAC) por rota.
* **Rate limit** por cliente/parceiro; **WAF** ativo com regras de API.
* Para **LLM**: **LLM Gateway** obrigatório (filtros input/output, PII masking, anti-prompt injection).

### 3.3 Performance & Capacidade

* **Latência** p50/p95/p99 ≤ SLO sob carga alvo (ex.: k6/Locust).
* **Throughput** sustentável (QPS) sem queda de acurácia ou *time outs*.
* **Uso de recursos** (CPU/GPU/RAM) dentro do *budget*; sem OOM.

### 3.4 Resiliência

* **Timeouts** e **retries** com *circuit breaker*; *backoff*.
* Degradação controlada quando **dependências** (feature store, cache, RAG store) estão lentas/fora.
* **Idempotência** de chamadas (evitar efeitos colaterais em replays).

### 3.5 Segurança funcional

* **Limits de saída**: *no NaN/Inf*, *range* de score/valores esperados.
* **Fairness spot-check** em *holdout* adicional / tráfego replay.
* **Auditoria**: logs mínimos com **mascara de PII**, correlação e decisão do modelo.

---

## 4) **Shadow Mode** (espelho sem impacto)

**Como funciona**

* O Gateway clona **X%** do tráfego real de produção e envia **em paralelo** ao candidato.
* Respostas **NÃO** são devolvidas ao cliente — apenas coletadas para análise.

**O que medir**

* **Delta de saída** vs. modelo atual (drift de score, taxa de decisão divergente).
* **Latência** do candidato sob tráfego real (inclui variações de payload).
* **Taxa de violação** de políticas LLM (se aplicável) e **incidentes** em *guardrails*.

**Gates típicos**

* |Δmétrica de negócio| ≤ **limiar** (ex.: +/- 1 pp em *approval rate*).
* **p95** ≤ SLO definido; **erro** ≤ X%.
* **0** vazamentos/violação de *guardrails*.

---

## 5) **Canary Release** (rollout progressivo com auto-rollback)

**Estratégia**

1. **Enable** 1% de tráfego real → medir por N minutos.
2. Se **PASS**, subir para 5% → medir.
3. Depois 25% → 50% → 100%.

**Gatilhos de rollback (automáticos)**

* **Latência p95** > SLO por 3 janelas consecutivas.
* **Erro 5xx** > limiar.
* **Drift de saída** acima do acordado vs. baseline.
* **Violação de política LLM** > 0 ocorrências críticas.
* **Alertas de custo** (custo/chamada supera *budget*).

**Observabilidade obrigatória**

* **OpenTelemetry** (traces) + métricas (latência, QPS, erro) + logs estruturados.
* **Dashboards**: *per-version* (vX vs vY), *per-client*, *per-route*.
* **Alertas**: Prometheus/Alertmanager (ou equivalente) com rotas claras de incidente.

---

## 6) Artefatos gerados

* `staging_report.json` — latência/erro/recursos, amostras de requests válidos/invalidos (sem PII).
* `shadow_eval.json` — divergência vs. baseline, fairness spot, violações de política.
* `canary_plan.md` — passos, SLOs, limiares, gatilhos, rollback.
* `rollout_decision.txt` — **PROCEED/HOLD/ROLLBACK** com timestamps e responsáveis.
* **Dashboards** salvos (links) + *alert rules* versionadas.

Todos anexados ao **run** no MLflow (Z4-2.6) e referenciados no **Z5**.

---

## 7) Exemplos rápidos

### 7.1 Esqueleto de **k6** para latência

```js
import http from 'k6/http';
import { sleep, check } from 'k6';

export let options = {
  vus: 50, duration: '5m',
  thresholds: {
    http_req_failed: ['rate<0.01'],
    http_req_duration: ['p(95)<120'] // p95 < 120ms
  }
};

export default function () {
  const payload = JSON.stringify({ /* features */ });
  const headers = { 'Content-Type': 'application/json', 'Authorization': `Bearer ${__ENV.TOKEN}` };
  const res = http.post(`${__ENV.URL}/v1/infer`, payload, { headers });
  check(res, { 'status 200': r => r.status === 200 });
  sleep(1);
}
```

### 7.2 **JSON Schema** do contrato de saída

```json
{
  "$schema": "https://json-schema.org/draft/2020-12/schema",
  "type": "object",
  "required": ["score","version","trace_id"],
  "properties": {
    "score": {"type":"number","minimum":0,"maximum":1},
    "version": {"type":"string"},
    "trace_id": {"type":"string"}
  }
}
```

### 7.3 **Gates** de canary (pseudo-OPA)

```rego
package canary

default proceed = false
proceed {
  input.metrics.latency_p95_ms <= 120
  input.metrics.error_rate <= 0.005
  input.metrics.delta_decision_pp <= 1.0
  input.security.llm_policy_violations == 0
}
```

---

## 8) Riscos × Controles × Frameworks

| Risco                                | Controles (Z4-2.10)                                              | Referências                             |
| ------------------------------------ | ---------------------------------------------------------------- | --------------------------------------- |
| Regressão em produção                | Shadow + Canary com **gates** e rollback                         | SRE (*SLI/SLO/Error budget*), OWASP API |
| Quebra de contrato de API            | JSON Schema/Pydantic + testes de contrato                        | NIST SP 800-53 SI-10, OWASP ASVS        |
| Latência/erro excessivos             | Teste de carga (k6/Locust), *autoscale*, *circuit breaker*       | SRE, NIST SC-5/SC-7                     |
| Vazamento/violação de política (LLM) | **LLM Gateway**, *prompt/output filtering*, monitor de violações | OWASP LLM Top 10, CSA AICM              |
| Observabilidade insuficiente         | OTel (traces), métricas, logs estruturados + alertas             | NIST AU-2/AU-12, CSA LOG                |
| Custo explosivo                      | Limites de QPS, *autoscale* sob budget, alertas de custo         | FinOps, SRE capacity planning           |

---

## 9) Runbooks (quando dá ruim)

* **Estouro de latência/erro no canary** → **rollback automático**, abrir incidente, coletar *traces*, comparar *pod* resources, revisar dependências (FS/RAG).
* **Divergência de decisão** > limiar → *hold*, analisar *feature drift* (Z9), revalidar *calibração*.
* **Violação de política LLM** → **rollback**, reforçar *guardrails* (input/output), revisar base RAG, adicionar **bloqueios**.
* **Custo acima do planejado** → reduzir QPS/autoescalar para baixo, otimizar *batching*/*quantization*, revisar *cache*.

---

## 10) Integrações (com outras zonas)

* **Z5 (Registry)**: o canary consome **somente** versões `Staging/Approved` com **assinatura válida**.
* **Z6 (Serving)**: incorpora **Inference Gateway** e **LLM Gateway** com as políticas validadas aqui.
* **Z9**: recebe métricas/alertas de staging/shadow/canary para trilhas e *post-mortems*.

---

## 11) Frase pronta para a entrevista

> “Antes de expor o modelo, eu valido em **Staging** com o mesmo *runtime*, rodo **Shadow Mode** espelhando tráfego real para medir **drift/latência** sem impacto, e faço **Canary** progressivo com **gates automáticos** (SLO, erro, segurança LLM). Com **OpenTelemetry** e *dashboards per-version*, qualquer violação **dispara rollback**. Só então o modelo é liberado para Z6.”
