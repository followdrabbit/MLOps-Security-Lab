# Z4-2.6 — **Experiment Tracking & Proveniência**

*garante reprodutibilidade, auditoria e “fio vermelho” Z3→Z4→Z5→Z6*

O **tracking & provenance** é o sistema nervoso da Z4. Ele registra **quem** treinou **o quê**, **com quais dados**, **qual código/ambiente**, **quais métricas**, **quais evidências de segurança** e **que artefatos** foram gerados/assinados. Sem isso, não há **reprodutibilidade**, **auditoria**, nem promoção segura para a Z5.

---

## 1) Objetivo & Princípios

**Objetivo:** produzir um trilho verificável “fim a fim” (dados → treino → avaliação → registro) com **metadados ricos** e **artefatos versionados**, possibilitando refazer o treino “bit-a-bit” e provar conformidade.

**Princípios**

* **Tudo versionado**: código, dados (snapshot/hash), imagem/container (por **digest**), hiperparâmetros e seeds.
* **Um único “run record”** por execução, com **artefatos anexados** (SBOM, relatórios de higiene e segurança, assinaturas).
* **Identidades e correlação**: OIDC da pessoa/serviço, `correlation_id` herdado das camadas anteriores, *lineage* Z3 ↔ Z4 ↔ Z5.
* **Imutabilidade**: nada “editável” pós-execução (apenas novos runs).
* **Reuso em produção**: metadados alimentam políticas e verificações na Z6.

---

## 2) O que **deve** ser registrado (campos obrigatórios)

| Categoria              | Campos mínimos (tags/params/artefatos)                                                                                           |
| ---------------------- | -------------------------------------------------------------------------------------------------------------------------------- |
| **Código & Build**     | `git_sha`, `repo_url`, `container_digest`, `sbom_ref`, `train_image_version`                                                     |
| **Dados**              | `dataset_id`, `dataset_snapshot_at`, `dataset_hash`, `feature_groups` (ex.: `fs_offline.risco_cliente_v1@v1`), `data_time_range` |
| **Execução**           | `run_id` (MLflow), `pipeline_id`, `job_id`, `orchestrator` (Airflow/K8s), `started_at`/`ended_at`, `seeds`                       |
| **Treino**             | `hyperparams` (todos), `train_val_test_split`, `hardware` (CPU/GPU/RAM), `egress_policy` (on/off)                                |
| **Métricas**           | métricas globais (AUC/F1/KS etc.) + **por subgrupo** (fairness)                                                                  |
| **Higiene (Z4-2.4)**   | `hygiene_report.json`, `dataset_manifest.json`, `privacy_report.json`, `leakage_checks.json`                                     |
| **Segurança (Z4-2.5)** | `adv_eval.json`, `privacy_eval.json`, `robustness_curves/*`, `output_integrity.json`, `security_decision.txt`                    |
| **Artefatos**          | `model_artifact_uri` (onnx/pt/wheel), `checksums` (sha256), **assinaturas cosign**, **attestation/provenance**                   |
| **Governança**         | `model_card.md` (finalidade, riscos, salvaguardas), `scdr_id`/`adr_id` (quando aplicável)                                        |
| **Correlação**         | `z1_correlation_id` (opcional), `broker_lineage_ref` (Z4-2.2), `z9_trace_id`                                                     |

> **Sem** esses itens, o run é **incompleto** → **não promove** na Z5.

---

## 3) Arquitetura de tracking (alto nível)

```
Z4 Treino/Jobs ──► MLflow Tracking (runs, params, metrics, artifacts)
         │                      │
         │                      ├─► Artifact Store (MinIO/S3, RO)
         │                      └─► Webhooks p/ Z9 (audit/metrics) e Z5 (pré-registro)
         └─► OpenLineage/Marquez (opcional)   ─► grafo de linhagem (Z3↔Z4↔Z5)
```

* **MLflow Tracking**: fonte primária (runs/param/metrics/artifacts/tags).
* **Artifact Store**: guarda **SBOM**, relatórios (Z4-2.4/2.5), pesos, assinaturas, *attestations*.
* **OpenLineage (opcional)**: grafo claro de **quem leu o quê** (dataset/feature) e **gerou o quê** (modelo).

---

## 4) Convenções de URIs, nomes e pastas

* **Run name**: `product-modelName-YYYYMMDD-HHMM-gitshort`
  ex.: `risk-default_v2-20251112-1030-a1b2c3d`
* **Artifact layout (no store)**:

```
artifacts/
  model/                             # pesos e config
  reports/
    hygiene/ (Z4-2.4)
    security/ (Z4-2.5)
    fairness/
  sbom/
    sbom.json
  signatures/
    model.sig         # assinatura do artefato
    container.intoto  # attestation SLSA
  checksums.json
  model_card.md
  metadata.json       # resumo do run para consumo rápido
```

---

## 5) Como **capturar** (exemplos práticos)

### 5.1 Inicialização do run (Python, MLflow)

```python
import mlflow, json, subprocess, os, time

mlflow.set_tracking_uri(os.getenv("MLFLOW_TRACKING_URI"))
mlflow.set_experiment("risk-default-v2")

with mlflow.start_run(run_name="risk-default_v2-20251112-1030-a1b2c3d") as run:
    # Código/Build
    git_sha = subprocess.check_output(["git","rev-parse","HEAD"]).decode().strip()
    mlflow.set_tags({
      "git_sha": git_sha,
      "container_digest": os.getenv("TRAIN_IMAGE_DIGEST"),
      "sbom_ref": "sbom/sbom.json",
      "orchestrator": "airflow",
      "pipeline_id": os.getenv("PIPELINE_ID","train_risco_model"),
      "job_id": os.getenv("JOB_ID",""),
    })

    # Dados (vindos do Access Broker / manifest Z3)
    manifest = json.load(open("manifests/dataset_manifest.json"))
    mlflow.set_tags({
      "dataset_id": manifest["dataset_id"],
      "dataset_snapshot_at": manifest["snapshot_at"],
      "dataset_hash": manifest["hash"],
      "feature_groups": ",".join(manifest["feature_groups"]),
      "data_time_range": manifest["time_range"]
    })

    # Hiperparâmetros & seeds
    mlflow.log_params(config["hyperparams"])
    mlflow.log_param("seed", config["seed"])
```

### 5.2 Registro de métricas & artefatos

```python
# Métricas (globais e por subgrupo)
mlflow.log_metric("auc", auc)
for grp, m in fairness_by_group.items():
    mlflow.log_metric(f"auc_group__{grp}", m["auc"])
    mlflow.log_metric(f"ks_group__{grp}", m["ks"])

# Artefatos fundamentais
mlflow.log_artifacts("reports/hygiene", artifact_path="reports/hygiene")
mlflow.log_artifacts("reports/security", artifact_path="reports/security")
mlflow.log_artifacts("sbom", artifact_path="sbom")
mlflow.log_artifacts("signatures", artifact_path="signatures")

# Modelo
mlflow.log_artifacts("model", artifact_path="model")

# Checksums (sha256 dos arquivos críticos)
mlflow.log_artifact("checksums.json")
```

### 5.3 Encerramento com decisão de promoção

```python
decision = open("reports/security/security_decision.txt").read().strip()
mlflow.set_tag("security_decision", decision)  # "PASS" ou "FAIL"
if decision != "PASS":
    raise SystemExit("Adversarial & Security Testing falhou — não promover.")
```

---

## 6) **Lineage** e correlação (Z3↔Z4↔Z5↔Z6)

* **Do lado dos dados (Z3)**: o Access Broker (Z4-2.2) envia (`broker_lineage_ref`) com `dataset@snapshot` e colunas/feature groups utilizados → gravar como **tag** do run.
* **Do lado do modelo (Z5)**: ao **registrar**, o pipeline envia o `run_id` + `model_version` + `cosign_sig` + `attestation` → o registro **referencia de volta** o run (link navegável).
* **Z6 (Serving)**: o *serving* lê **somente** modelos com `security_decision=PASS` e **valida assinatura**/attestation na carga. No *startup*, reporta para Z9: `model_version`, `run_id`, `container_digest`.
* **Correlação operacional**: `z1_correlation_id` pode acompanhar eventos de ingestão de dados até runs de treino (Z9).

---

## 7) “Reproducibility bundle” (como refazer o treino)

Para cada run **PASS**, gere um pacote “refaça em 1 comando”:

* `repro/manifest.json`

  * `git_sha`, `container_digest`, `dataset_id@snapshot`, `feature_groups@version`, `hyperparams`, `seed`, `sbom_ref`, `attestation_ref`.
* `repro/run.sh`

  * script que puxa **a mesma** imagem por **digest**, monta o snapshot de dados (somente leitura via broker), aplica os mesmos *params*, fixa *seeds* e reenvia métricas ao MLflow em um novo run (marcado como `rebuild_of=<run_id>`).

> **Política:** modelos **sem** reproducibility bundle **não** são elegíveis à promoção.

---

## 8) Integrações chave

* **CI/CD (Z4-2.3)**: publica SBOM, assina imagem e artefatos, empurra *attestations* → **tags**/artefatos do run.
* **Higiene (Z4-2.4)** e **Adversarial (Z4-2.5)**: sempre anexam relatórios; **security_decision** governa a promoção.
* **Registry (Z5)**: recebe `run_id`, hashes, assinaturas e `model_card.md`. O “**Prod Model Registry**” é a **única** fonte para Z6.
* **Observabilidade (Z9)**: coleta logs de tracking e expõe dashboards de **drill-down** por `run_id`/`model_version`.

---

## 9) Riscos × Controles × Frameworks

| Risco                      | Controles (Z4-2.6)                                                                               | Referências                                      |
| -------------------------- | ------------------------------------------------------------------------------------------------ | ------------------------------------------------ |
| Falta de reprodutibilidade | `git_sha`, `container_digest`, pins/locks, snapshot/hash de dados, seeds, reproducibility bundle | NIST AI RMF (Manage/Measure), CSA AICM (LOG/SEF) |
| Supply chain obscura       | SBOM, assinaturas, attestation (SLSA), *immutable artifacts*                                     | NIST SP 800-53 SA-*, CM-*, SLSA                  |
| Auditoria deficiente       | MLflow + artifacts, *lineage* Z3/Z4/Z5, eventos Z9                                               | NIST AU-2/6, CSA LOG                             |
| Promoção indevida          | `security_decision=PASS`, checagem na Z5/Z6, política “no evidence, no deploy”                   | OWASP ML / GenAI; NIST AI RMF                    |
| Vieses não documentados    | métricas por subgrupo + `model_card.md`                                                          | NIST AI RMF (Map/Measure)                        |

---

## 10) Runbooks

* **Run sem SBOM/assinatura** → marcar `security_decision=FAIL`, barrar promoção, reexecutar build com scanners e cosign.
* **Dados sem snapshot/hash** → invalidar run; corrigir **Access Broker** para sempre fornecer manifest.
* **Divergência de métrica ao refazer** → conferir seeds, `container_digest`, `dataset_hash`; investigar *nondeterminism* (CUDA/cuDNN), fixar *flags determinísticas*.
* **Run “huérfano” no Registry** (sem link ao MLflow) → bloquear disponibilização na Z6 até corrigir vínculo.

---

## 11) Frase pronta para a entrevista

> “**Cada treino gera um registro completo (MLflow)** com `git_sha`, `container_digest`, `dataset@snapshot`, seeds, hiperparâmetros, **SBOM**, **assinaturas** e **relatórios de higiene/adversarial**. Esse run é referenciado no **Registry (Z5)** e validado na **Z6**. Com isso, consigo **refazer** qualquer modelo e **provar** integridade, privacidade e robustez antes de entrar em produção.”
