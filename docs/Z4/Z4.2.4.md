# Z4-2.4 — Data & Label **Hygiene** (Pré-treino)

*o “check-in sanitário” antes de gastar GPU — e antes de contaminar modelos*

A **higiene de dados e rótulos** é uma esteira automática que roda **antes** do treino.
Ela valida **estrutura, conteúdo, temporalidade, privacidade, balanceamento e leakage**, produz **evidências** e **bloqueia** o pipeline se algo crítico falhar.
Integra diretamente os contratos/qualidade da **Z3** e registra tudo no **MLflow/Z9**.

---

## 1) Objetivo & Princípios

**Objetivo:** garantir que o conjunto de treino é **válido, autorizado e ético**, com **proveniência clara** e **riscos controlados** (poisoning, leakage, viés, PII).

**Princípios**

* **Contratos primeiro** (schema & catálogo da Z3 são a fonte da verdade).
* **Fail-fast** para que falhas baratas ocorram antes do uso de GPU.
* **Minimização** (somente colunas necessárias ao experimento).
* **Temporalidade correta** (nada do futuro vazando para o passado).
* **Reprodutibilidade** (snapshot + hashes + seeds).
* **Evidência ou não aconteceu** (relatórios anexados ao run).

---

## 2) O que é verificado (checklist por categoria)

### 2.1 Estrutura & Contrato (Dataset Contract)

* **Schema aderente** (tipos, colunas obrigatórias, domínios/enum).
* **Chaves & unicidade** (ex.: `customer_id+event_ts` único).
* **Chaves estrangeiras** resolvidas (joins consistentes com dimensões).
* **Particionamento válido** (datas/cortes esperados).

### 2.2 Conteúdo (Sanidade & Plausibilidade)

* **Nulos** em campos críticos (e.g., rótulo não nulo no *train/val*).
* **Ranges plausíveis** (valor ≥ 0, datas ≥ 2000-01-01, etc.).
* **Regras cruzadas** (se `channel=ATM`, então `device_id` vazio, p.ex.).
* **Outliers grosseiros** (IQR/robusto *z-score*) → *flag/quarentena*.

### 2.3 Duplicidades & Quase-duplicidades

* **Exatas** (hash SHA-256 de linhas/chaves).
* **Quase** (texto: *simhash*; imagem: *perceptual hash*) quando aplicável.
* Política: **drop** ou **consolidar** com justificativa registrada.

### 2.4 Privacidade, PII & Base Legal

* **Somente** colunas permitidas (catálogo Z3).
* **PII mascarada/tokenizada** por padrão; **clear-text** só com policy.
* **Finalidade declarada** (purpose) compatível com o projeto (ABAC).
* **Proveniência** de consentimento/base legal (LGPD) para atributos sensíveis.

### 2.5 Temporalidade & **Leakage**

* **Série temporal correta** (split *time-aware*: *train* < *val* < *test*).
* **Label availability lag** (respeitar atraso real do rótulo).
* **Target leakage**:

  * features calculadas **após** o evento ou **derivadas** do rótulo → **bloqueio**;
  * correlação “suspeita” (≈1.0) com o rótulo → investigar.
* **Group-aware split** (cliente/dispositivo não aparece em múltiplos folds).

### 2.6 Balanceamento & Representatividade de Rótulos

* **Distribuição de classes** (fraude/defaut raros requerem estratégias).
* **Cobertura por subgrupos** (sexo, região, faixa etária, etc. — quando permitido).
* **Métricas de *fairness* de entrada** (mín. registros por grupo; *skew* inicial).

### 2.7 *Poisoning* & Anomalias Sutilezas

* Padrões **craftados** (ex.: ondas de valores mínimos/iguais por fonte).
* “**Bursts**” concentrados por IP/dispositivo/conta.
* **Mudanças abruptas** em distribuições vs. baseline (PSI/KL).

### 2.8 Versão, Snapshot & Hashes

* **dataset_id**, **snapshot_at**, **hash** de partições/arquivos.
* Guardar **baseline de distribuição** (q1, mediana, q3, hist) para drift futuro.

---

## 3) Severidade & Gates (como decide PASS/FAIL)

| Severidade  | Exemplos                                                                                            | Ação                                            |
| ----------- | --------------------------------------------------------------------------------------------------- | ----------------------------------------------- |
| **CRÍTICO** | schema divergente, PII sem base legal, leakage temporal/target, rótulo ausente, assinatura inválida | **FAIL** imediato (interrompe pipeline)         |
| **ALTO**    | duplicatas massivas, outliers extremos, desbalanceamento severo sem estratégia definida             | **FAIL** ou **HOLD** até correção/justificativa |
| **MÉDIO**   | nulos moderados em campos não críticos, leve *skew* de subgrupos                                    | **WARN** (prossegue com *flag*)                 |
| **BAIXO**   | *drift* mínimo, campos opcionais ausentes                                                           | **INFO**                                        |

*As decisões e limiares vivem versionados no repositório (`hygiene_policy.yml`).*

---

## 4) Produção de Evidências (o que vai para o run)

* `hygiene_report.json` (resumo, severidades, métricas de qualidade).
* `dataset_manifest.json` (dataset_id, snapshot, hashes, partições, fonte).
* `privacy_report.json` (colunas PII, masking/tokenização aplicada).
* `leakage_checks.json` (temporal, target, group leakage).
* Estatísticas de distribuição (para baseline & futuro drift).
* Tudo anexado ao **MLflow** e enviado à **Z9**.

---

## 5) Exemplos (SQL & Python)

### 5.1 Regras simples em SQL (Postgres)

```sql
-- Not null em rótulo
ALTER TABLE train.labels
  ALTER COLUMN is_fraud SET NOT NULL;

-- Range plausível
ALTER TABLE train.transactions
  ADD CONSTRAINT chk_amount_nonneg CHECK (amount >= 0);

-- Unicidade por chave + tempo
CREATE UNIQUE INDEX ux_tx ON train.transactions (customer_id, event_ts);

-- RLS para treino (separação por projeto/time)
ALTER TABLE train.transactions ENABLE ROW LEVEL SECURITY;
CREATE POLICY rlsp_train ON train.transactions
  USING ( current_setting('app.project') = project_tag );
```

### 5.2 Validações com **Great Expectations** (Python)

```python
import great_expectations as ge
df = ge.from_pandas(train_df)

df.expect_column_to_exist("label")
df.expect_column_values_to_not_be_null("label")
df.expect_column_values_to_be_between("amount", min_value=0)
df.expect_table_row_count_to_be_between(min_value=10000)
df.expect_compound_columns_to_be_unique(["customer_id","event_ts"])

# Domínios/enum
df.expect_column_values_to_be_in_set("channel", {"APP","WEB","ATM"})

# Exporta relatório
res = df.validate()
res_json = res.to_json_dict()
```

### 5.3 Checagem de **leakage temporal** (Python)

```python
assert train_df["feature_ts"].max() <= train_df["label_ts"].min(), \
    "Temporal leakage: feature posterior ao rótulo!"

# Split time-aware
train = data[data.event_ts < "2025-10-01"]
val   = data[(data.event_ts >= "2025-10-01") & (data.event_ts < "2025-11-01")]
test  = data[data.event_ts >= "2025-11-01"]
```

### 5.4 *Baseline* de distribuição e **PSI**

```python
import numpy as np

def psi(expected, actual, bins=10):
    e_hist, b = np.histogram(expected, bins=bins)
    a_hist, _ = np.histogram(actual,   bins=b)
    e = (e_hist + 1e-6)/e_hist.sum()
    a = (a_hist + 1e-6)/a_hist.sum()
    return np.sum((a - e) * np.log(a/e))

psi_amount = psi(baseline["amount"], current["amount"])
```

---

## 6) Integração no Pipeline (com Z4-2.3)

1. **Step `hygiene:prepare`**

   * Busca **contratos** da Z3 (schema, sensibilidade).
   * Carrega `hygiene_policy.yml` (limiares).

2. **Step `hygiene:run`**

   * Executa checks (2.1–2.7).
   * Gera relatórios/artefatos.

3. **Step `hygiene:gate`**

   * Avalia severidades vs. política.
   * **FAIL/WARN/INFO** + saída padronizada para o orquestrador.

4. **Step `record`**

   * Anexa ao **MLflow** (run atual).
   * Emite eventos para **Z9**.

> Se **FAIL**, o pipeline **não** prossegue para treino.
> Se **PASS/WARN**, segue para **Z4-2.5 (Adversarial & Security Testing)**.

---

## 7) Casos especiais (dados não tabulares / LLM)

* **Texto/LLM**:

  * *Dedup* agressivo, remoção de PII, filtros de tóxico/ódio, licenças/ToS;
  * Anti-*prompt injection* em dados de *instruction tuning*;
  * Checar **contaminação** do *test set* (overlap n-gram).

* **Imagens/áudio**:

  * *Perceptual hash* para *dedup*, normalização, checagem de formatos;
  * Metadados potencialmente sensíveis → remover/mascarar.

---

## 8) Riscos × Controles × Frameworks

| Risco                       | Controles (esta seção)                               | Referências                       |
| --------------------------- | ---------------------------------------------------- | --------------------------------- |
| **Data/Label Poisoning**    | 2.2/2.3/2.7 + baseline vs. PSI/KL + bursts/anomalias | OWASP ML (ML02), NIST AI RMF      |
| **Target/Temporal Leakage** | 2.5 (splits time-aware, lag, group-aware)            | OWASP ML (ML08), boas práticas TS |
| **PII & Uso Indevido**      | 2.4 (catalog/ABAC, masking/token), minimização       | LGPD/GDPR, NIST AC-6/PL-8         |
| **Bias/Representatividade** | 2.6 (coverage & fairness pré-treino)                 | NIST AI RMF (Measure/Manage)      |
| **Skew & Drift precoce**    | 2.8 (baseline dist.), PSI/KL registrados             | Observabilidade Z3/Z9             |
| **Reprodutibilidade fraca** | snapshot + hashes + manifests                        | Dev/ML reproducibility patterns   |

---

## 9) Runbooks (quando dá ruim)

* **Falha CRÍTICA (leakage/PII)** → **para pipeline**, abre incidente, referencia dataset/snapshot, notifica Z3 e segurança; registrar SCDR/ADR.
* **Desbalanceamento severo** → definir estratégia (re-amostragem, *class weights*), documentar no Model Card.
* **Anomalias de bursts** → traçar origem (Z0/Z1/Z2 lineage), quarentenar partições afetadas, reprocessar.
* **Contratos quebrados** → bloquear fonte no **Access Broker** (Z4-2.2) e ajustar produtor/ingestão (Z1/Z3).

---

## 10) Saídas esperadas (para colar no seu README)

* `reports/hygiene_report.json`
* `reports/privacy_report.json`
* `reports/leakage_checks.json`
* `reports/distribution_baseline/*.json`
* `manifests/dataset_manifest.json`

> Esses artefatos são **prérequisitos** para:
> **Z4-2.5 (Adversarial & Security Testing)** → **Z4-2.7 (Assinatura)** → **Z5 (Registry)**.
