# Z6-2.4 — Feature Retrieval Proxy

*(Cache • ABAC por tenant • mTLS • Point-in-Time Correctness • Fallback seguro)*

## 1) Papel e posicionamento

O **Feature Retrieval Proxy** é a “frente segura” para **buscar features on-line** (baixa latência) usadas pelos serviços de predição (Z6-2.3). Ele fica **entre o serviço do modelo** e o(s) **repositório(s) de features** (Redis/Feast/Key-Value DB), aplicando **autorização fina**, **políticas de dados**, **cache** e **controles de consistência**.

> Objetivo: entregar **features corretas no tempo**, apenas **as permitidas** para a **identidade/tenant** da chamada, com **baixa latência**, **trilha de auditoria** e **fallback** previsível.

---

## 2) Capacidades obrigatórias

### 2.1 Autenticação, Autorização e Multi-tenant (ABAC)

* **AuthN**: mTLS ou JWT *service-to-service* (emitido pelo IdP).
* **AuthZ (ABAC)**: política por **tenant/app/modelo/rota**, determinando **quais entidades/coleções** e **quais features** cada cliente pode ler.
* **Escopos**: `features:read:<collection>`, `entity:<type>`, `tenant:<id>`.
* **Row/Entity-level ACL**: chave de entidade (ex.: `customer_id`) só é consultável se pertencer ao **tenant**/autorização do chamador.

### 2.2 Comunicação e rede

* **mTLS** fim-a-fim**:** proxy ⇄ store(s) (Redis/Feast) ⇄ serviços auxiliares.
* **NetworkPolicies** *deny-by-default* com *allowlist* apenas para portas/hosts necessários.
* **Sem acesso internet** a partir do proxy.

### 2.3 Catálogo e contrato de features

* **Allowlist de colunas/features** por **modelo/versão** (evita exfiltração de PII não usada).
* **Tipos/intervalos** validados (ex.: `age:int [0..120]`).
* **Mapeamento de nomes**: dicionário estável (`feature_view.feature_name → tipo/semântica`).
* **Transformações idênticas** às do treino (reuso de *feature definitions*; evita **training-serving skew**).

### 2.4 Point-in-Time Correctness (as-of)

* **Parâmetro `as_of`** (timestamp) obrigatório/derivado (evento de predição).
* Retorna **o último valor ≤ as_of** para cada feature (**sem “ver o futuro”**).
* **Skew guard**: rejeitar `as_of` muito à frente (ex.: >60s do relógio do proxy).
* **Consistência**: preferir **eventual com bound** (ex.: *staleness* < N s) ou **strong** se o store suportar.

### 2.5 Cache e desempenho

* **Camadas**:

  * *in-process* (no pod) para *hot keys*;
  * **Redis** front para *shared cache* (TTL curto);
  * (opcional) *near-cache* por AZ.
* **TTL por feature** (ex.: estáticas 24h, dinâmicas 5–30s).
* **Negative caching** (evita martelar o store para chaves ausentes).
* **Prefetch/Warmup** para rotas quentes do modelo.
* **Limites**: *concurrency cap* por cliente; *token bucket* por rota.

### 2.6 Fallback e *degraded mode*

* **Fallback hierárquico**: cache → valor default → **não responder** (configurável).
* **Default explícito** por feature (ex.: média global, sentinel).
* **Sem “chutar”**: se a política exigir precisão, **melhor 503 do que dado errado**.

### 2.7 Privacidade e sensibilidade

* **Classificação** no catálogo (PII/Confidencial/Interno).
* **Mascaramento/tokenização** na borda quando o consumidor não tem permissão de ver valor bruto.
* **Hash/HMAC** para identificadores (ex.: `customer_id_hmac`) com **chaves no Vault** (não logar valores reais).

### 2.8 Observabilidade e auditoria

* **Logs estruturados**: `request_id`, `tenant`, `model`, `version`, `entity_keys`, `hit/miss`, `as_of`, `staleness_ms`, **sem valores de features**.
* **Métricas**: hit-rate, p95/p99, erros por razão (miss/deny/timeout), *staleness* média, custo.
* **Tracing**: correlação com a predição (Z9).

---

## 3) Fluxos de referência

### 3.1 Leitura simples (1 entidade → N features)

1. Serviço do modelo chama o **Proxy** com `tenant`, `entity_id`, `as_of`, `feature_set`.
2. Proxy **autoriza** (ABAC), valida `as_of`, aplica **allowlist** e busca no cache.
3. **Cache hit** → retorna; **miss** → consulta store → atualiza cache → retorna.
4. Registra **latência, staleness, hit/miss**, sem logar valores.

### 3.2 Leitura em lote (M entidades → N features)

1. Mesma lógica, mas por *batch*; **coalescing** de chaves para reduzir *round-trips*.
2. **Limite** de tamanho e **paginado** para não saturar a memória.

### 3.3 Fallback

1. Store indisponível → tenta **segunda réplica**;
2. Se ainda falhar → **cache**; se inválido → **default** (se permitido); caso contrário → **503**.

---

## 4) Políticas — exemplos (pseudo-Rego)

### 4.1 Allowlist de features por modelo/versão

```rego
package features.allow
default permit = false

permit {
  input.model == "churn"
  input.version == "v2"
  allowed := {
    "demographics.age",
    "account.tenure_days",
    "tx.avg_amount_30d",
    "tx.count_30d"
  }
  every f in input.requested_features {
    f in allowed
  }
}
```

### 4.2 ABAC por tenant/entidade

```rego
package features.abac
default allow = false

allow {
  input.tenant == input.entity.tenant
  input.scopes[_] == concat("","features:read:", input.collection)
}
```

### 4.3 Point-in-Time Correctness

```rego
package features.pit
default ok = false

ok {
  input.as_of <= now()
  input.as_of >= now() - input.policy.max_skew_seconds
}
```

---

## 5) Exemplos de implementação (trechos)

### 5.1 Kubernetes — Deployment (resumo)

```yaml
apiVersion: apps/v1
kind: Deployment
metadata:
  name: feat-proxy
spec:
  replicas: 2
  template:
    spec:
      serviceAccountName: sa-feat-proxy
      containers:
      - name: proxy
        image: registry.local/ml/feature-proxy:1.2.0
        ports: [{ containerPort: 7070 }]
        env:
          - name: CACHE_REDIS_URL
            valueFrom: { secretKeyRef: { name: feat-secrets, key: redis_url } }
          - name: TTL_TX_DYN
            value: "15s"
          - name: TTL_STATIC
            value: "24h"
        securityContext:
          runAsNonRoot: true
          allowPrivilegeEscalation: false
          readOnlyRootFilesystem: true
        resources:
          requests: { cpu: "200m", memory: "256Mi" }
          limits:   { cpu: "1",    memory: "1Gi" }
```

### 5.2 NetworkPolicy (só modelo e Redis)

```yaml
apiVersion: networking.k8s.io/v1
kind: NetworkPolicy
metadata:
  name: np-feat-proxy
spec:
  podSelector: { matchLabels: { app: feat-proxy } }
  policyTypes: ["Ingress","Egress"]
  ingress:
  - from:
    - podSelector: { matchLabels: { app: churn-v2 } }
    ports: [{ protocol: TCP, port: 7070 }]
  egress:
  - to:
    - podSelector: { matchLabels: { app: redis-features } }
    ports: [{ protocol: TCP, port: 6379 }]
```

### 5.3 Esqueleto de API (FastAPI — ilustração)

```python
@app.post("/features/get")
def get_features(req: Request):
    ctx = authorize(req)           # valida JWT/mTLS, tenant, scopes
    assert_pit(req.as_of)          # point-in-time correctness
    allowlist_check(ctx, req.set)  # contrato de features por modelo/versão
    vals = cache.get_many(req.keys, req.set, req.as_of)
    miss = [k for k,v in vals.items() if v is None]
    if miss:
        fetched = store.fetch_many(miss, req.set, req.as_of)
        cache.put_many(fetched, ttl=ttl_for(req.set))
        vals.update(fetched)
    resp = redact_if_needed(ctx, vals)  # tokenização/mascara se necessário
    audit_log(ctx, req, vals=None)      # nunca logar valores
    return resp
```

---

## 6) Checklists operacionais

**Antes do go-live**

* [ ] **ABAC/allowlist** por modelo/versão testado (positivo/negativo).
* [ ] **Point-in-time** ativado (obrigatório) + *skew guard*.
* [ ] **TTLs** definidos por feature set; **negative cache** ligado.
* [ ] **Fallbacks** documentados (defaults vs 503).
* [ ] **mTLS**, NetworkPolicies e segredos via Vault.
* [ ] Dashboards: **hit-rate**, **p95**, **staleness**, **erros**.

**Durante operação**

* [ ] Hit-rate ≥ meta (ex.: 80%); ajustar TTL/warmup.
* [ ] *Staleness* dentro do *budget* (ex.: < 10s p95 para `tx.*`).
* [ ] Anomalias de acesso (entity-IDs fora do tenant).
* [ ] Auditoria de mudanças em catálogos/allowlists.

---

## 7) Riscos × Controles (recorte do proxy)

| Risco                                      | Controles no Feature Proxy                                              |
| ------------------------------------------ | ----------------------------------------------------------------------- |
| Exfiltração de PII/colunas sensíveis       | **Allowlist** por modelo/versão; **mascara/tokeniza** quando necessário |
| Cross-tenant / acesso indevido a entidades | **ABAC** por tenant/coleção/entidade; verificação da chave de entidade  |
| **Training-Serving Skew**                  | Reuso de **feature definitions**; validação de tipos/ranges             |
| “Ver o futuro” (leak temporal)             | **Point-in-time correctness** + *skew guard*                            |
| DoS no store de features                   | **Cache** multi-nível; rate-limit/concurrency; negative caching         |
| Dados incorretos no fallback               | Defaults **explícitos** e por política; preferir 503 quando obrigatório |
| Vazamento por logs                         | Logs sem valores; hash/ID apenas; retenção/mascara                      |

---

## 8) Integrações

* **Z3 (Curated/Feature Store)**: origem das features e *definitions*; dual-write on-line/off-line.
* **Z6-2.3 (Serving)**: consumidor principal; passa `tenant/as_of/keys`.
* **Z8 (IAM/Vault/KMS/DLP)**: identidade, segredos de stores, tokenização/HMAC.
* **Z9 (Monitoring & Audit)**: métricas de **hit-rate, staleness, latência** e logs de decisão.

---

## 9) Frases prontas (entrevista)

* “O **Feature Proxy** garante **Point-in-Time Correctness**: só devolve valores **≤ as_of**, evitando *label leakage*.”
* “Aplicamos **ABAC e allowlists** por **modelo/versão**, então o serviço de predição **nunca** enxerga **PII fora de contrato**.”
* “**Cache multi-nível** com **negative caching** protege o store e reduz latência; definimos **TTLs por feature set**.”
* “Se não posso garantir precisão, **prefiro 503** a devolver dado incorreto. Fallbacks são **explícitos e auditáveis**.”
