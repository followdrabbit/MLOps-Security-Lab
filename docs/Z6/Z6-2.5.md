# Z6-2.5 — Batch Inference Orchestrator

*(Airflow/Argo/Spark • Service Accounts • Versão Fixada • Reprodutibilidade • Saída Governada)*

## 1) Papel e posicionamento

O **Batch Inference Orchestrator** executa **predições em lote** (alta vazão) com **modelos aprovados** da Z5, lendo **somente** conjuntos de dados **autorizados** (Z3) e escrevendo **exclusivamente** em **Scored Output Store** (Z6-2.6). Ele garante **reprodutibilidade**, **governança**, **segurança de dados** e **auditoria** ponta-a-ponta.

> Objetivo: produzir *scores* confiáveis, com **modelo/versão fixados**, **lineage completo** e **controles de acesso** — sem “atalhos” diretos para sistemas core (Z7).

---

## 2) Capacidades obrigatórias

### 2.1 Identidade, segredos e isolamento

* **Service Account dedicada** por pipeline/lote (princípio do menor privilégio).
* **Segredos via Vault Agent** (credenciais de leitura Z3, escrita Z6-2.6, chaves KMS).
* **Ambiente efêmero/hardening**: contêiner não-root, FS read-only, no-new-privs, **NetworkPolicies** *deny-by-default*.
* **mTLS** para stores e registry; **TLS** para todos os *endpoints*.

### 2.2 Pinagem de versão e cadeia de suprimentos do modelo

* **Modelo/versão fixados** por execução (ex.: `model=churn@digest:sha256:...`).
* **Verificação** de assinatura/digest/attestations ao **iniciar** o job.
* **Registro** do *policy digest* e *config hash* no *manifest* da execução.

### 2.3 Contrato de dados e leitura autorizada (Z3)

* **Allowlist** de **datasets/colunas/partições** por pipeline.
* **Point-in-time correctness** quando houver chave temporal (`as_of` da carga).
* **Minimização de dados**: apenas campos necessários às features/regras de saída.
* **PII-aware**: *joins* por IDs **tokenizados/HMAC** quando aplicável (chave no Vault).

### 2.4 Escalabilidade, performance e integridade

* **Paralelismo controlado** (Spark/Beam/Dask ou *workers* paralelos).
* **Backpressure** e **limites de throughput** por *partition window*.
* **Idempotência** por **job_id + input_partition** (re-run não duplica saída).
* **Exactly-once**: escrever em destino **temporário** e **commit atômico** (rename/move).

### 2.5 Qualidade, sanidade e segurança dos insumos

* **Checks de sanidade**: *nulls* críticos, ranges mínimos, cardinalidades, *duplicates*.
* **Drift/Anomalias de entrada** (leve) **antes** do scoring: se *z-score* > limiar → **fail-fast** ou **degradar** (política).
* **Bloqueio** se dataset fora do contrato (colunas extras/ausentes).

### 2.6 Saída governada e contrato com Z7

* Escrever **apenas** em **Scored Output Store** (Z6-2.6), partições versionadas por `dt`/`batch_id`.
* **Esquema de saída** padronizado: `entity_key`, `model_name`, `model_version`, `score`, `explanations?`, `as_of_in`, `as_of_out`, `metadata`.
* **Sem escrita direta** em Core/Risk/Fraud; integração via **APIs com contrato** na Z7.

### 2.7 Observabilidade, *lineage* e manifestos

* **Manifesto da execução** (JSON): `job_id`, `model_digest`, `dataset_id`, `rows_in/out`, *checks*, *metrics*, *artifacts*.
* **Logs estruturados** (sem PII), **métricas** (taxa, p95, erro por partição) e **tracing** (do orquestrador ao storage).
* **Auditoria** enviada à Z9.

### 2.8 Custo/SLO e janelas operacionais

* Janela de execução (ex.: *off-peak*), **limite de custo** (se houver cobrança por compute/storage).
* **SLOs** de término e reprocessamento (SLA de D-1, por ex.).
* **Retentiva** e **expurgo**: *checkpointing*/limpeza de *staging*.

---

## 3) Fluxos de referência

### 3.1 Lote diário (alto nível)

1. **Sensor do Registry** confirma `model@digest` **Approved** (Z5).
2. **Sensor de dados** confirma partições de entrada (Z3) disponíveis e válidas.
3. **Preparação**: *snapshot* de *configs*, *policy digest*, *seed* RNG (determinismo).
4. **Scoring**: particiona entradas, aplica pré-processamento **igual ao treino**, executa inferência.
5. **Validações de saída**: *nulls*, faixas de `score`, distribuição (sanidade).
6. **Commit atômico** em **Scored Output** + **manifest.json** + **métricas**.
7. **Publicação** de evento para Z7 (opcional) e **auditoria** para Z9.

### 3.2 Reprocessamento idempotente

* Forçar `job_id` + `input_partition` idênticos → escreve sobre *staging* e **re-commita** (mesma partição destino).
* Dedupe por **chave idempotente** na *landing* de saída.

---

## 4) Políticas — exemplos (pseudo-Rego)

### 4.1 Somente modelo aprovado e não revogado

```rego
package batch.model
default allow = false
allow {
  input.model.stage == "Approved"
  input.model.revoked == false
  input.model.digest == input.expected_digest
}
```

### 4.2 Dataset/colunas permitidos

```rego
package batch.data
default permit = false
permit {
  input.dataset.id == "curated/tx_2025"
  allowed := {"cust_id_hmac","amount_30d","count_30d","tenure_days"}
  every c in input.columns { c in allowed }
}
```

### 4.3 Idempotência e janela

```rego
package batch.run
default ok = false
ok {
  not input.already_committed[input.job_id]
  input.window == "off-peak"
}
```

---

## 5) Exemplos de implementação (trechos)

### 5.1 Airflow — DAG (Python, esqueleto)

```python
from airflow import DAG
from airflow.operators.python import PythonOperator
from datetime import datetime
import json, hashlib

def verify_model(**ctx):
    # consulta Z5 (registry): retorna digest/assinatura/policy
    reg = ctx['ti'].xcom_pull(task_ids='get_registry_info')
    assert reg['stage'] == 'Approved' and not reg['revoked']
    ctx['ti'].xcom_push(key='model_digest', value=reg['digest'])

def score_partition(**ctx):
    digest = ctx['ti'].xcom_pull(key='model_digest', task_ids='verify_model')
    part = ctx['params']['partition']
    # 1) load features from Z3 (allowlist)
    # 2) load model artifact (verificar assinatura/digest)
    # 3) inferência; validar ranges e nulls
    # 4) escrever em /scored/tmp/{job_id}/{part} (atomic staging)

def commit_atomic(**ctx):
    # move /scored/tmp/{job_id} -> /scored/dt=YYYY-MM-DD/job_id=...
    pass

with DAG("batch_churn_v2", start_date=datetime(2025,11,1), schedule="@daily", catchup=False) as dag:
    get_registry_info = PythonOperator(task_id="get_registry_info", python_callable=lambda: ...)
    verify = PythonOperator(task_id="verify_model", python_callable=verify_model)
    score = PythonOperator(task_id="score", python_callable=score_partition, params={"partition": "dt={{ ds }}"})
    commit = PythonOperator(task_id="commit", python_callable=commit_atomic)
    get_registry_info >> verify >> score >> commit
```

### 5.2 Manifesto da execução (exemplo)

```json
{
  "job_id": "batch_churn_v2_2025-11-13",
  "model": { "name": "churn", "version": "2.3.1", "digest": "sha256:..." },
  "inputs": { "dataset": "curated/tx_2025", "partition": "dt=2025-11-12" },
  "policy_digest": "sha256:...",
  "rows_in": 12503456,
  "rows_out": 12503456,
  "sanity_checks": { "null_rate": 0.0003, "score_range": [0.001, 0.997] },
  "metrics": { "latency_sec_total": 412, "throughput_rps": 30350 },
  "as_of": "2025-11-12T23:59:59Z",
  "artifact_store": "s3://scored/churn/dt=2025-11-12/job_id=batch_churn_v2_2025-11-13"
}
```

### 5.3 Exactly-once (padrão de commit)

* **Escrever** em `s3://scored/tmp/{job_id}/part=*`
* **Validar** contagem/checagens
* **Mover** (rename/commit) para `s3://scored/dt=.../job_id=...`
* **Marcar** *success flag* (`_SUCCESS`) e **emitir evento** (Z9)

---

## 6) Checklists operacionais

**Antes do go-live**

* [ ] **Service Accounts** e **Vault Agent** (segredos dinâmicos).
* [ ] **Verificação de assinatura/digest** do modelo.
* [ ] **Allowlist** de datasets/colunas e **PIT correctness** configurados.
* [ ] **Idempotência** por `job_id+partition` e **commit atômico** testados.
* [ ] **Sanity & drift checks** definidos com *thresholds* e ações.
* [ ] **Schema de saída** + **manifesto** + **auditoria** integrados à Z9.

**Durante operação**

* [ ] Acompanhar **tempo total**, **p95** e **erro por partição**.
* [ ] Alarmes para **falha de sensor de dados** e **revogação** no Registry.
* [ ] Revisar *burn rate* de SLO e custo de compute.
* [ ] Reprocessamentos seguem **chave idempotente** e **dedupe**.

---

## 7) Riscos × Controles (recorte do batch)

| Risco                                       | Controles no Orchestrator                                                       |
| ------------------------------------------- | ------------------------------------------------------------------------------- |
| Usar modelo errado/alterado                 | Verificação de **assinatura/digest/attestations**; **pinagem** por execução     |
| Ler dados fora do contrato                  | **Allowlist** de datasets/colunas/partições; **PIT correctness**                |
| Duplicidade/erros em reprocessamento        | **Idempotência** (job_id+partition); **commit atômico**; dedupe                 |
| Vazamento de PII                            | Minimização/mascara/tokenização; *joins* por **HMAC**; logs sem dados sensíveis |
| Data poisoning silencioso (entrada anômala) | **Sanity & drift checks** antes do scoring; **fail-fast/degrade**               |
| Bypass para sistemas core                   | Escrita **apenas** em **Scored Output**; integração com Z7 via **APIs**         |
| Escalada lateral/segredos expostos          | SA dedicada, **Vault Agent**, mTLS, **NetworkPolicies**, contêiner **não-root** |

---

## 8) Integrações

* **Z5 (Registry & Governance):** sensor de aprovação, digest, revogação, *policy digest*.
* **Z3 (Curated/Feature Store):** datasets/autorização; *feature definitions* alinhadas ao treino.
* **Z6-2.6 (Scored Output Store):** destino único; partições versionadas; contrato de esquema.
* **Z7 (Consumers):** consumo via **APIs com contrato** (sem escrita direta).
* **Z8 (IAM/Vault/KMS):** identidades técnicas, segredos e chaves.
* **Z9 (Monitoring & Audit):** logs, métricas, *lineage* e manifestos.

---

## 9) Frases prontas (entrevista)

* “Cada execução **fixa o modelo por digest** e **verifica assinatura**; a saída vem com **manifesto** e *lineage* completo.”
* “Leio **apenas** Z3 autorizado, com **point-in-time**; aplico **sanity/drift checks** antes do scoring — se violar, **fail-fast**.”
* “A saída **sempre** vai para **Scored Output Store**; **nunca** gravamos direto nos sistemas core. Integração só via **APIs com contrato**.”
* “Reprocessamentos são **idempotentes** e o **commit é atômico** — garantindo **exactly-once** na prática.”
