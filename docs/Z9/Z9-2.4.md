# Z9-2.4 — Drift & Bias Monitoring (Dados, Features e Modelos)

↩️ Voltar: [Z9 — Monitoring, Observability & Audit](./Z9-index.md) · [README (Mapa Z0–Z9)](../../README.md)

> **Resumo**: Detecta **mudanças de distribuição** (data/feature drift), **mudanças de conceito** (concept drift), **label drift** e **viés** em produção (online/batch). Gera **métricas**, **alertas**, evidencia para **auditoria** e **gatilhos** para *retrain* / *rollback* via Z5 (governança).

---

## 1) Objetivos & escopo

**Objetivos**

* Medir continuamente **saúde de dados e modelos** em produção.
* Identificar **drifts** que afetam acurácia/robustez (e.g., covariate shift, prior shift).
* Monitorar **fairness/viés** conforme obrigações regulatórias (setor financeiro/privacidade).
* Orquestrar **respostas**: *shadow tests*, *rollback*, *re-treino*, *feature freeze*.

**Escopo**

* **Z3/Z6/Z7**: coleta de amostras de entrada/saída e métricas de inferência.
* **Batch & Online**: janelas deslizantes, comparação com **baseline** (treino/validação).
* **Ground truth atrasado**: acoplar feedback real (quando disponível) ao painel.

---

## 2) Conceitos essenciais (terminologia clara)

* **Data/Feature drift**: distribuição (P(X)) muda (ex.: PSI alto, KS p-valor baixo).
* **Concept drift**: relação (P(Y|X)) muda (modelo correto “ontem”, errado “hoje”).
* **Label drift / Prior shift**: (P(Y)) muda (ex.: proporção de fraude).
* **Fairness/viés**: performance desigual entre **grupos sensíveis** (p.ex., sexo/raça/idade) — *usar apenas atributos permitidos e com base legal*.
* **Baseline**: distribuição de referência (treino/validação/primeiro deploy).
* **Janela**: período de agregação (ex.: 1h online; D+1 batch).

---

## 3) O que medir (SLIs de drift & bias)

### 3.1 Dados & features

* **PSI** (Population Stability Index) por feature.
* **Distâncias/divergências**: KS (contínuas), Chi-quadrado (categóricas), **Jensen-Shannon**/**KL** (quando fizer sentido).
* **Missing/novas categorias**; **cardinalidade** inesperada; **faixas inválidas**.

### 3.2 Saída/modelo

* **Score drift** (ex.: média/variância do *score*).
* **Calibração** (Brier, ECE) quando houver *ground truth*.
* **Acurácia/AUC/F1** em janelas com *labels* (retroalimentação).

### 3.3 Fairness (quando aplicável)

* **Demographic Parity** (dif. taxas de positivo).
* **Equalized Odds** (TPR/FPR por grupo).
* **Equal Opportunity** (TPR por grupo).
* **PPV/NPV** por grupo (quando relevante ao risco de crédito/fraude).

> **Privacidade/Ética**: só calcule métricas por grupo se houver **base legal**, minimização e controles de acesso. Preferir **pseudonimização** e **agregação**.

---

## 4) Como medir (pipeline de monitoração)

1. **Coleta** (Z6/Z7): amostras de entradas/saídas (sem PII), *scores*, *latências* e *metadata* (`model.version`, `policy_digest`).
2. **Agregação** (Z9): janelas (ex.: 15m, 1h, 24h) + **baseline** (treino/val/primeiro mês).
3. **Cálculo**: PSI/KS/etc. + métricas de performance/fairness.
4. **Avaliação**: comparar com **limiares** (ex.: PSI < 0.1 OK; 0.1–0.25 atenção; > 0.25 alerta).
5. **Ação**: alertar SOC/SRE e **gatinhos automatizados** (abaixo).

---

## 5) Ações automáticas (playbooks)

* **Atenção**: abrir ticket, marcar painel, aumentar amostragem de *traces*.
* **Alerta**: **ativar shadow/canary** com versão anterior; travar *autoscale* de TPS; **DLP/Policy** mais estrita se sinais de abuso.
* **Crítico**: **rollback** do modelo (via Z5), congelar *feature pipeline* afetada, iniciar **ciclo de re-treino** supervisionado (Z4), convocar **comitê de risco**.

> **Integração com Z5**: qualquer *swap* de versão deve registrar **evidence** (assinatura/attestation) e **motivo** (drift/bias), auditável.

---

## 6) Limiares sugeridos (exemplos)

* **PSI** por feature:

  * `< 0.10` OK · `0.10 – 0.25` **atenção** · `> 0.25` **alerta**.
* **KS** (p-valor): `< 0.05` sugere drift (investigar).
* **Score drift**: 3σ acima do baseline → atenção; 5σ → alerta.
* **Fairness**: *parity* entre 0.8–1.25 **atenção**; fora disso **alerta** (ajustar ao caso de uso/regulação).

> **Importante**: definir **limiares por produto/rota** (Z7) e documentar justificativas no **ADR/SCDR**.

---

## 7) Painéis (dashboards)

* **Visão executiva**: saúde por modelo (verde/amarelo/vermelho), *top features* com maior PSI, *swap* de versão por drift.
* **Dados/Features (Z3)**: PSI/KS por tabela/coluna, *missing*, *novas categorias*, *lineage* até Z0/Z1.
* **Serving (Z6)**: drift de *scores*, latência, erros; comparação versão atual vs. anterior (*shadow*).
* **Fairness**: métricas por grupo (quando aplicável), *trend lines*, *intervalos de confiança*.
* **Investigação**: correlação *drift ↔ rejeições de ingestão (WAF/AV/CDR)*, *drift ↔ custo/abuso* (Z7).

---

## 8) Exemplos práticos

### 8.1 PSI (pseudocódigo)

```python
def psi(expected, actual, bins=10):
    # expected/actual: arrays 1-D
    q = np.quantile(expected, np.linspace(0, 1, bins+1))
    e_hist = np.histogram(expected, q)[0] / len(expected)
    a_hist = np.histogram(actual,   q)[0] / len(actual)
    # suavização para evitar div/0
    e_hist = np.clip(e_hist, 1e-6, None)
    a_hist = np.clip(a_hist, 1e-6, None)
    return np.sum((a_hist - e_hist) * np.log(a_hist / e_hist))
```

### 8.2 PromQL — alerta de drift

```promql
psi_value{model_name="churn", feature="age"} > 0.25
```

### 8.3 Canary/shadow (estratégia)

* **Shadow**: duplicar tráfego para `model=v_prev` (respostas descartadas), comparar *latência/score drift*.
* **Canary**: 5% de tráfego real em `v_new` com *SLO guard* (rollback automático em caso de violação).

---

## 9) Riscos × Controles × Frameworks

| Risco real                                 | Controles deste módulo                                         | Encaixe arquitetural                   |
| ------------------------------------------ | -------------------------------------------------------------- | -------------------------------------- |
| **Queda de acurácia por mudança de dados** | PSI/KS/JS em janelas + alertas + shadow/canary + *retrain*     | Z6 (coleta) → Z9 (cálculo) → Z5 (swap) |
| **Viés/fairness degradado**                | Métricas de paridade/odds, *access reviews* e comitê de ética  | Z9 (métricas) ↔ Z8 (governança)        |
| **Exploração/adversarial shift**           | Detecção de padrões anômalos, *rate limit*, *red team prompts* | Z6 filtros ↔ Z9 anomalias              |
| **Investigações sem evidência**            | Logs/traces correlacionados, *evidence store* de mudanças      | Z9 ↔ Z8-2.8 (evidências)               |

**Referenciais úteis**

* **NIST AI RMF** (Map/Measure/Manage/Govern): medir e tomar decisão baseada em risco.
* **CSA AI Controls Matrix (AICM)**: *Data Quality & Integrity*, *Model Monitoring*.
* **OWASP LLM Top 10** (para LLMs): sinais de *prompt injection* e *data exfil* correlacionados ao drift de saída.

---

## 10) Checklists

**Antes do go-live**

* [ ] Definir **baseline** (treino/val) e **janelas** (online/batch).
* [ ] Publicar **limiares** por modelo/rota e justificar no **ADR/SCDR**.
* [ ] Configurar **coleta** (Z6/Z7) e **pipelines de cálculo** no Z9.
* [ ] Preparar **playbooks** de *shadow/canary/rollback/retrain*.

**Operação**

* [ ] Rever **limiares** trimestralmente; recalibrar após grandes mudanças.
* [ ] Auditar **decisões de swap** (motivo, evidência, impacto).
* [ ] Monitorar **fairness** (se aplicável) com *access reviews* e *privacy by design*.

---

## 11) Frases-chave (entrevista)

* “Eu monitoro **PSI/KS** por feature e **score drift** por versão, com **gatilhos automatizados** para *shadow/canary/rollback*.”
* “Quando tenho *ground truth*, acompanho **calibração** e **AUC** por janela; se não, uso **proxies robustos** de drift.”
* “**Fairness** é tratado como risco: métricas por grupo **apenas** quando houver base legal, com **governança** na Z8 e **evidências** para auditoria.”
